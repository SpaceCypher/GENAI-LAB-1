{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCF-zQLcdLgm"
   },
   "source": [
    "# Travel Destination Extractor\n",
    "\n",
    "## Objective\n",
    "This project extracts travel destinations (locations such as cities, countries, and landmarks)\n",
    "from travel-related text using Named Entity Recognition (NER) with Hugging Face pipelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ygun6ahNdOJT"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-d3dxHWUdaj2"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344,
     "referenced_widgets": [
      "1a2d3cb92aad48379cd139fb8524f9af",
      "96e0e6bb82a4477c94b8137996d4afb8",
      "4f7d42409d174740898e1184f77744f8",
      "5978694b4fc64f79b25fa8ee8cd064c1",
      "f30cfa94b30d43c7bcdd84df930d0734",
      "71a90e36b34d499c90a91e085f93a1df",
      "b988f9835e3241cc98235dd57ddd8779",
      "36d45d03c6d0487092369ded9eb9f6be",
      "a841f0ee1c1c41ac846665f4155c361c",
      "7a6a50ae30824872a10d6ba955429436",
      "5c079b066bca44ff86377adb2929d574",
      "0b99fc1275f8486d9f2fbed07d77a162",
      "fff9236d09bd4d9b8eaa7a46f081783d",
      "04a7cadbd6ec4d79b17c87835bc0cfb2",
      "8cc8901a88374685952d750858ee2b89",
      "700aee1a5d2c486385b7028c8a8ac68e",
      "fb91355c89bb45fc948a900274ca896e",
      "a7a3e2840f6f4ea9851c43e1aec7630d",
      "e5454158df524b19ae0fccb23273cdbb",
      "5a287bd2a8044f37af4adcdae9272af1",
      "db1ff19e162040fab7bfb9f4cd1cd6b3",
      "abc7d2ecb4ba48febbc1e060cbd55107",
      "5114c120e88f4c29b7f72755208a05d0",
      "4196106f68a54ba4ae2e3f8f14f02e24",
      "08c6e31529484a729b4b2084007ef818",
      "5bf043482a704d1ca246f9c5a755fca5",
      "0103f246049547e384e9293807963d24",
      "4e97469924e148d5855d3485426360b4",
      "0e5c893840bc4f9d9700c68cbe0560f3",
      "fcbcbabf97044ee4951d6d57389fc1be",
      "d01e8b4e37bb40399654b8cfba02d7f5",
      "6c1d0c3067e44c5c8d09203d35aaf5d5",
      "24e8c727110e48b4ae5963f554ba8d95",
      "3a2a723764664b5ca0b95c9355f0e858",
      "bae7472fdd7943b09ed198677d62c267",
      "a3a8fa7b963c488385a4f15c4796f73a",
      "a4f52c5ecd8647d793693888aa1d9272",
      "bf645ad8bff3479382f9085fb7530790",
      "304f0c6fc8b74a2884c954c8d3c77f49",
      "b6b30f0cf52b4808bfb7c1081c10217b",
      "604081f087d248c4be2d4ab4faafc850",
      "69a078e9f45246faa43aaa8b0239d629",
      "5cfcbc7de4624f689794b5c4095bd8e8",
      "ab7a4c25b2424aeda7fcc55196519637"
     ]
    },
    "id": "afQOw6ikddJM",
    "outputId": "e2004051-35da-4956-91cb-fc1d723c9844"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2d3cb92aad48379cd139fb8524f9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b99fc1275f8486d9f2fbed07d77a162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5114c120e88f4c29b7f72755208a05d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2a723764664b5ca0b95c9355f0e858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "ner_pipeline = pipeline(\n",
    "    \"ner\",\n",
    "    model=\"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "    aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQiQ99gcdfE6"
   },
   "outputs": [],
   "source": [
    "travel_text = \"\"\"\n",
    "Last summer I visited Paris and Rome before heading to the Swiss Alps near Zurich.\n",
    "After that, I flew to New York and later relaxed on the beaches of Bali.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PXW-X87Rdgiq",
    "outputId": "87ed51b0-affc-4694-a24e-7cd3f748bf23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity_group': 'LOC', 'score': np.float32(0.9996213), 'word': 'Paris', 'start': 23, 'end': 28}\n",
      "{'entity_group': 'LOC', 'score': np.float32(0.99957436), 'word': 'Rome', 'start': 33, 'end': 37}\n",
      "{'entity_group': 'LOC', 'score': np.float32(0.7993264), 'word': 'Swiss Alps', 'start': 60, 'end': 70}\n",
      "{'entity_group': 'LOC', 'score': np.float32(0.99964654), 'word': 'Zurich', 'start': 76, 'end': 82}\n",
      "{'entity_group': 'LOC', 'score': np.float32(0.99947214), 'word': 'New York', 'start': 106, 'end': 114}\n",
      "{'entity_group': 'LOC', 'score': np.float32(0.99922574), 'word': 'Bali', 'start': 151, 'end': 155}\n"
     ]
    }
   ],
   "source": [
    "entities = ner_pipeline(travel_text)\n",
    "\n",
    "for entity in entities:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4ocmuhidiWh",
    "outputId": "4863903c-dd30-48ce-9caf-d59e3010ea6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Travel Destinations:\n",
      "- Zurich\n",
      "- New York\n",
      "- Swiss Alps\n",
      "- Paris\n",
      "- Bali\n",
      "- Rome\n"
     ]
    }
   ],
   "source": [
    "destinations = []\n",
    "\n",
    "for entity in entities:\n",
    "    if entity[\"entity_group\"] in [\"LOC\", \"GPE\"]:\n",
    "        destinations.append(entity[\"word\"])\n",
    "\n",
    "print(\"Extracted Travel Destinations:\")\n",
    "for place in set(destinations):\n",
    "    print(\"-\", place)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyZQeZFcdls8"
   },
   "source": [
    "## Explanation\n",
    "\n",
    "This project uses a transformer-based Named Entity Recognition (NER) pipeline to identify\n",
    "location entities from unstructured travel text.\n",
    "\n",
    "The underlying model is a BERT-based encoder fine-tuned for NER tasks, which makes it suitable\n",
    "for extracting place names such as cities, countries, and landmarks. This demonstrates how\n",
    "pre-trained NLP models can be applied to real-world information extraction problems without\n",
    "additional training.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
